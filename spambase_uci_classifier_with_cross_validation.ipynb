{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spambase uci classifier with cross validation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhvaniVora25/Spambase-UCI-Classifier/blob/master/spambase_uci_classifier_with_cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "flHVzsAov4MR",
        "colab_type": "code",
        "outputId": "a2119de9-4657-42df-8630-058afb693df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jxyde_4ZwAXg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks')\n",
        "\n",
        "#spambase data from UCI has been stored in google drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ip0neFtOs6J-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "df = pd.read_csv('spambase.data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L_BlXKy4v2EW",
        "colab_type": "code",
        "outputId": "8d5510a3-470c-48ad-ebb5-195a31ccbd94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Percentage of spams in the data: \")\n",
        "df['class'].value_counts()*100/df['class'].count()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of spams in the data: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    60.595523\n",
              "1    39.404477\n",
              "Name: class, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "hUYACdniEG8e",
        "colab_type": "code",
        "outputId": "3d83a6f7-8b6f-4bfc-9715-2edab50f63e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make</th>\n",
              "      <th>word_freq_address</th>\n",
              "      <th>word_freq_all</th>\n",
              "      <th>word_freq_3d</th>\n",
              "      <th>word_freq_our</th>\n",
              "      <th>word_freq_over</th>\n",
              "      <th>word_freq_remove</th>\n",
              "      <th>word_freq_internet</th>\n",
              "      <th>word_freq_order</th>\n",
              "      <th>word_freq_mail</th>\n",
              "      <th>...</th>\n",
              "      <th>char_freq_;</th>\n",
              "      <th>char_freq_(</th>\n",
              "      <th>char_freq_[</th>\n",
              "      <th>char_freq_!</th>\n",
              "      <th>char_freq_$</th>\n",
              "      <th>char_freq_#</th>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <th>capital_run_length_total</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.104553</td>\n",
              "      <td>0.213015</td>\n",
              "      <td>0.280656</td>\n",
              "      <td>0.065425</td>\n",
              "      <td>0.312223</td>\n",
              "      <td>0.095901</td>\n",
              "      <td>0.114208</td>\n",
              "      <td>0.105295</td>\n",
              "      <td>0.090067</td>\n",
              "      <td>0.239413</td>\n",
              "      <td>...</td>\n",
              "      <td>0.038575</td>\n",
              "      <td>0.139030</td>\n",
              "      <td>0.016976</td>\n",
              "      <td>0.269071</td>\n",
              "      <td>0.075811</td>\n",
              "      <td>0.044238</td>\n",
              "      <td>5.191515</td>\n",
              "      <td>52.172789</td>\n",
              "      <td>283.289285</td>\n",
              "      <td>0.394045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.305358</td>\n",
              "      <td>1.290575</td>\n",
              "      <td>0.504143</td>\n",
              "      <td>1.395151</td>\n",
              "      <td>0.672513</td>\n",
              "      <td>0.273824</td>\n",
              "      <td>0.391441</td>\n",
              "      <td>0.401071</td>\n",
              "      <td>0.278616</td>\n",
              "      <td>0.644755</td>\n",
              "      <td>...</td>\n",
              "      <td>0.243471</td>\n",
              "      <td>0.270355</td>\n",
              "      <td>0.109394</td>\n",
              "      <td>0.815672</td>\n",
              "      <td>0.245882</td>\n",
              "      <td>0.429342</td>\n",
              "      <td>31.729449</td>\n",
              "      <td>194.891310</td>\n",
              "      <td>606.347851</td>\n",
              "      <td>0.488698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.588000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.276000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.188000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.052000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.706000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>266.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.540000</td>\n",
              "      <td>14.280000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>42.810000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.880000</td>\n",
              "      <td>7.270000</td>\n",
              "      <td>11.110000</td>\n",
              "      <td>5.260000</td>\n",
              "      <td>18.180000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.385000</td>\n",
              "      <td>9.752000</td>\n",
              "      <td>4.081000</td>\n",
              "      <td>32.478000</td>\n",
              "      <td>6.003000</td>\n",
              "      <td>19.829000</td>\n",
              "      <td>1102.500000</td>\n",
              "      <td>9989.000000</td>\n",
              "      <td>15841.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 58 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
              "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
              "mean         0.104553           0.213015       0.280656      0.065425   \n",
              "std          0.305358           1.290575       0.504143      1.395151   \n",
              "min          0.000000           0.000000       0.000000      0.000000   \n",
              "25%          0.000000           0.000000       0.000000      0.000000   \n",
              "50%          0.000000           0.000000       0.000000      0.000000   \n",
              "75%          0.000000           0.000000       0.420000      0.000000   \n",
              "max          4.540000          14.280000       5.100000     42.810000   \n",
              "\n",
              "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
              "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
              "mean        0.312223        0.095901          0.114208            0.105295   \n",
              "std         0.672513        0.273824          0.391441            0.401071   \n",
              "min         0.000000        0.000000          0.000000            0.000000   \n",
              "25%         0.000000        0.000000          0.000000            0.000000   \n",
              "50%         0.000000        0.000000          0.000000            0.000000   \n",
              "75%         0.380000        0.000000          0.000000            0.000000   \n",
              "max        10.000000        5.880000          7.270000           11.110000   \n",
              "\n",
              "       word_freq_order  word_freq_mail     ...       char_freq_;  char_freq_(  \\\n",
              "count      4601.000000     4601.000000     ...       4601.000000  4601.000000   \n",
              "mean          0.090067        0.239413     ...          0.038575     0.139030   \n",
              "std           0.278616        0.644755     ...          0.243471     0.270355   \n",
              "min           0.000000        0.000000     ...          0.000000     0.000000   \n",
              "25%           0.000000        0.000000     ...          0.000000     0.000000   \n",
              "50%           0.000000        0.000000     ...          0.000000     0.065000   \n",
              "75%           0.000000        0.160000     ...          0.000000     0.188000   \n",
              "max           5.260000       18.180000     ...          4.385000     9.752000   \n",
              "\n",
              "       char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
              "count  4601.000000  4601.000000  4601.000000  4601.000000   \n",
              "mean      0.016976     0.269071     0.075811     0.044238   \n",
              "std       0.109394     0.815672     0.245882     0.429342   \n",
              "min       0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.315000     0.052000     0.000000   \n",
              "max       4.081000    32.478000     6.003000    19.829000   \n",
              "\n",
              "       capital_run_length_average  capital_run_length_longest  \\\n",
              "count                 4601.000000                 4601.000000   \n",
              "mean                     5.191515                   52.172789   \n",
              "std                     31.729449                  194.891310   \n",
              "min                      1.000000                    1.000000   \n",
              "25%                      1.588000                    6.000000   \n",
              "50%                      2.276000                   15.000000   \n",
              "75%                      3.706000                   43.000000   \n",
              "max                   1102.500000                 9989.000000   \n",
              "\n",
              "       capital_run_length_total        class  \n",
              "count               4601.000000  4601.000000  \n",
              "mean                 283.289285     0.394045  \n",
              "std                  606.347851     0.488698  \n",
              "min                    1.000000     0.000000  \n",
              "25%                   35.000000     0.000000  \n",
              "50%                   95.000000     0.000000  \n",
              "75%                  266.000000     1.000000  \n",
              "max                15841.000000     1.000000  \n",
              "\n",
              "[8 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "CdIjVFcFwFRV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = df[\"class\"]\n",
        "X = df.drop('class', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EfIfp1lXJDDe",
        "colab_type": "code",
        "outputId": "bc549e0c-f407-4731-c2f6-45a3c9ec5faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Understanding the capital runs attributes in the data set, \n",
        "whose upper bound is not given\n",
        "\"\"\"\n",
        "X.capital_run_length_longest.hist(bins=25)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1fb9e77898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPy/1ObMHvlAhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "p4JSbe1DC554",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Logistic Regression with normalization and cross validation"
      ]
    },
    {
      "metadata": {
        "id": "ZuhzlWGqMvu0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creating the confusion matrix storing mechanism for every cross fold"
      ]
    },
    {
      "metadata": {
        "id": "JnLHIGiuI-9f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, make_scorer\n",
        "import numpy as np\n",
        "\n",
        "\"\"\"\n",
        "The Scikit-learn confusion matrix: \n",
        "\n",
        "true negative : 0 classified as 0\n",
        "false positive : 0 classified as 1\n",
        "false negative : 1 classified as 0\n",
        "true positive : 1 classified as 1\n",
        "\n",
        "in our case, \n",
        "false positive: non spam classified as spam / non spam testing examples (0 classified as 1/class=0) \n",
        "                = fp / tn + fp\n",
        "false negative: spam classified as non spam / spam testing examples (1 classified as 0/class=1)\n",
        "                = fn / fn + tp\n",
        "overall error rate: overall misclassified examples / all examples (0 classified as 1 and 1 classified as 0/ num of examples)\n",
        "                = fp + fn / (tp + fp + fn + tn)\n",
        "\"\"\"\n",
        "\n",
        "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0,0]\n",
        "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0,1]\n",
        "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1,0]\n",
        "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1,1]\n",
        "\n",
        "def fpf(y_true, y_pred): return fp(y_true, y_pred) / (tn(y_true, y_pred) + fp(y_true, y_pred))\n",
        "def fnf(y_true, y_pred): return fn(y_true, y_pred) / (fn(y_true, y_pred) + tp(y_true, y_pred))\n",
        "def oer(y_true, y_pred): return (fp(y_true, y_pred) + fn(y_true, y_pred) )/( tn(y_true, y_pred) + fp(y_true, y_pred) + fn(y_true, y_pred) + tp(y_true, y_pred))\n",
        "\n",
        "scoring = {\n",
        "    'tp':make_scorer(tp),\n",
        "    'tn':make_scorer(tn),\n",
        "    'fp':make_scorer(fp),\n",
        "    'fn':make_scorer(fn)\n",
        "}\n",
        "\n",
        "score = {\n",
        "    'fp':make_scorer(fpf),\n",
        "    'fn':make_scorer(fnf),\n",
        "    'oe':make_scorer(oer)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VeiNttVzBLy9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "def results(estimator, X, y, k):\n",
        "  scores = cross_validate(estimator=estimator,X=normalized_X,scoring=score, y=y, cv = k)\n",
        "\n",
        "  table = []\n",
        "\n",
        "  for i in range(k):\n",
        "    m = [scores['test_fp'][i], scores['test_fn'][i], scores['test_oe'][i]]\n",
        "    table.append(m)\n",
        "\n",
        "\n",
        "  avg = np.sum(np.array(table), axis = 0, keepdims=True)/k\n",
        "\n",
        "\n",
        "  matrix = pd.DataFrame(table, columns = ['False Positives','False Negatives','Overall Error'])\n",
        "  print(\"Errors for each cross fold: \")\n",
        "  print(matrix)\n",
        "  print(\"\\nAverage errors across all folds:\\n\")\n",
        "  print(\"False Positives: {}\\nFalse Negatives: {}\\nOverall Error Rate: {}\\n\".format(avg[0][0],avg[0][1],avg[0][2]))\n",
        "  \n",
        "  return matrix, avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j1eCT4BQM2cd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Normalizing the data set and applying logistic regression and AdaBoost on the dataset, with confusion matrix as the scoring mechanism"
      ]
    },
    {
      "metadata": {
        "id": "GjICVOB1B3Ww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "4c8052ee-89e3-487d-8463-19e4a9619380"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "k = 5\n",
        "normalized_X=(X-X.min())/(X.max()-X.min())\n",
        "\n",
        "clf = LogisticRegression(random_state=1,multi_class='ovr', solver='lbfgs')\n",
        "\n",
        "\n",
        "print(\"Logistic Regression: \\n\")\n",
        "_, _ = results(clf, normalized_X, y, k)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression: \n",
            "\n",
            "Errors for each cross fold: \n",
            "   False Positives  False Negatives  Overall Error\n",
            "0         0.037634         0.245179       0.119435\n",
            "1         0.064516         0.203857       0.119435\n",
            "2         0.059140         0.159780       0.098806\n",
            "3         0.023339         0.176796       0.083787\n",
            "4         0.192101         0.223757       0.204570\n",
            "\n",
            "Average errors across all folds:\n",
            "\n",
            "False Positives: 0.07534603579081485\n",
            "False Negatives: 0.2018735826370181\n",
            "Overall Error Rate: 0.12520666966761537\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5n_kfY_SDSOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "8d4a308b-8b3d-4c98-cf99-fbf2b0e2777d"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
        "                         algorithm=\"SAMME.R\",\n",
        "                         n_estimators=200)\n",
        "print(\"AdaBoost: \\n\")\n",
        "_, _ = results(bdt, normalized_X, y, k)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoost: \n",
            "\n",
            "Errors for each cross fold: \n",
            "   False Positives  False Negatives  Overall Error\n",
            "0         0.043011         0.090909       0.061889\n",
            "1         0.032258         0.090909       0.055375\n",
            "2         0.051971         0.052342       0.052117\n",
            "3         0.028725         0.077348       0.047878\n",
            "4         0.236984         0.160221       0.206746\n",
            "\n",
            "Average errors across all folds:\n",
            "\n",
            "False Positives: 0.0785898599126143\n",
            "False Negatives: 0.09434576807756115\n",
            "Overall Error Rate: 0.08480113988792519\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m2TL8KKe84Vg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Other classifying algorithms that I have tried are in the second Jupyter Notebook in the repository"
      ]
    }
  ]
}