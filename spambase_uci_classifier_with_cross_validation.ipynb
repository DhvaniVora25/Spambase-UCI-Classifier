{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spambase uci classifier with cross validation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhvaniVora25/Spambase-UCI-Classifier/blob/master/spambase_uci_classifier_with_cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "flHVzsAov4MR",
        "colab_type": "code",
        "outputId": "37dbc71d-b490-4d10-b1ae-989023b63c49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jxyde_4ZwAXg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks')\n",
        "\n",
        "#spambase data from UCI has been stored in google drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ip0neFtOs6J-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "df = pd.read_csv('spambase.data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L_BlXKy4v2EW",
        "colab_type": "code",
        "outputId": "0a15d59e-638c-42d3-b660-9597e1098aeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Percentage of spams in the data: \")\n",
        "df['class'].value_counts()*100/df['class'].count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of spams in the data: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    60.595523\n",
              "1    39.404477\n",
              "Name: class, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "hUYACdniEG8e",
        "colab_type": "code",
        "outputId": "cad6d6e8-c903-4879-c14e-29def71ba51c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make</th>\n",
              "      <th>word_freq_address</th>\n",
              "      <th>word_freq_all</th>\n",
              "      <th>word_freq_3d</th>\n",
              "      <th>word_freq_our</th>\n",
              "      <th>word_freq_over</th>\n",
              "      <th>word_freq_remove</th>\n",
              "      <th>word_freq_internet</th>\n",
              "      <th>word_freq_order</th>\n",
              "      <th>word_freq_mail</th>\n",
              "      <th>...</th>\n",
              "      <th>char_freq_;</th>\n",
              "      <th>char_freq_(</th>\n",
              "      <th>char_freq_[</th>\n",
              "      <th>char_freq_!</th>\n",
              "      <th>char_freq_$</th>\n",
              "      <th>char_freq_#</th>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <th>capital_run_length_total</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.104553</td>\n",
              "      <td>0.213015</td>\n",
              "      <td>0.280656</td>\n",
              "      <td>0.065425</td>\n",
              "      <td>0.312223</td>\n",
              "      <td>0.095901</td>\n",
              "      <td>0.114208</td>\n",
              "      <td>0.105295</td>\n",
              "      <td>0.090067</td>\n",
              "      <td>0.239413</td>\n",
              "      <td>...</td>\n",
              "      <td>0.038575</td>\n",
              "      <td>0.139030</td>\n",
              "      <td>0.016976</td>\n",
              "      <td>0.269071</td>\n",
              "      <td>0.075811</td>\n",
              "      <td>0.044238</td>\n",
              "      <td>5.191515</td>\n",
              "      <td>52.172789</td>\n",
              "      <td>283.289285</td>\n",
              "      <td>0.394045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.305358</td>\n",
              "      <td>1.290575</td>\n",
              "      <td>0.504143</td>\n",
              "      <td>1.395151</td>\n",
              "      <td>0.672513</td>\n",
              "      <td>0.273824</td>\n",
              "      <td>0.391441</td>\n",
              "      <td>0.401071</td>\n",
              "      <td>0.278616</td>\n",
              "      <td>0.644755</td>\n",
              "      <td>...</td>\n",
              "      <td>0.243471</td>\n",
              "      <td>0.270355</td>\n",
              "      <td>0.109394</td>\n",
              "      <td>0.815672</td>\n",
              "      <td>0.245882</td>\n",
              "      <td>0.429342</td>\n",
              "      <td>31.729449</td>\n",
              "      <td>194.891310</td>\n",
              "      <td>606.347851</td>\n",
              "      <td>0.488698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.588000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.276000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.188000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.052000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.706000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>266.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.540000</td>\n",
              "      <td>14.280000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>42.810000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.880000</td>\n",
              "      <td>7.270000</td>\n",
              "      <td>11.110000</td>\n",
              "      <td>5.260000</td>\n",
              "      <td>18.180000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.385000</td>\n",
              "      <td>9.752000</td>\n",
              "      <td>4.081000</td>\n",
              "      <td>32.478000</td>\n",
              "      <td>6.003000</td>\n",
              "      <td>19.829000</td>\n",
              "      <td>1102.500000</td>\n",
              "      <td>9989.000000</td>\n",
              "      <td>15841.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 58 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
              "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
              "mean         0.104553           0.213015       0.280656      0.065425   \n",
              "std          0.305358           1.290575       0.504143      1.395151   \n",
              "min          0.000000           0.000000       0.000000      0.000000   \n",
              "25%          0.000000           0.000000       0.000000      0.000000   \n",
              "50%          0.000000           0.000000       0.000000      0.000000   \n",
              "75%          0.000000           0.000000       0.420000      0.000000   \n",
              "max          4.540000          14.280000       5.100000     42.810000   \n",
              "\n",
              "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
              "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
              "mean        0.312223        0.095901          0.114208            0.105295   \n",
              "std         0.672513        0.273824          0.391441            0.401071   \n",
              "min         0.000000        0.000000          0.000000            0.000000   \n",
              "25%         0.000000        0.000000          0.000000            0.000000   \n",
              "50%         0.000000        0.000000          0.000000            0.000000   \n",
              "75%         0.380000        0.000000          0.000000            0.000000   \n",
              "max        10.000000        5.880000          7.270000           11.110000   \n",
              "\n",
              "       word_freq_order  word_freq_mail     ...       char_freq_;  char_freq_(  \\\n",
              "count      4601.000000     4601.000000     ...       4601.000000  4601.000000   \n",
              "mean          0.090067        0.239413     ...          0.038575     0.139030   \n",
              "std           0.278616        0.644755     ...          0.243471     0.270355   \n",
              "min           0.000000        0.000000     ...          0.000000     0.000000   \n",
              "25%           0.000000        0.000000     ...          0.000000     0.000000   \n",
              "50%           0.000000        0.000000     ...          0.000000     0.065000   \n",
              "75%           0.000000        0.160000     ...          0.000000     0.188000   \n",
              "max           5.260000       18.180000     ...          4.385000     9.752000   \n",
              "\n",
              "       char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
              "count  4601.000000  4601.000000  4601.000000  4601.000000   \n",
              "mean      0.016976     0.269071     0.075811     0.044238   \n",
              "std       0.109394     0.815672     0.245882     0.429342   \n",
              "min       0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.315000     0.052000     0.000000   \n",
              "max       4.081000    32.478000     6.003000    19.829000   \n",
              "\n",
              "       capital_run_length_average  capital_run_length_longest  \\\n",
              "count                 4601.000000                 4601.000000   \n",
              "mean                     5.191515                   52.172789   \n",
              "std                     31.729449                  194.891310   \n",
              "min                      1.000000                    1.000000   \n",
              "25%                      1.588000                    6.000000   \n",
              "50%                      2.276000                   15.000000   \n",
              "75%                      3.706000                   43.000000   \n",
              "max                   1102.500000                 9989.000000   \n",
              "\n",
              "       capital_run_length_total        class  \n",
              "count               4601.000000  4601.000000  \n",
              "mean                 283.289285     0.394045  \n",
              "std                  606.347851     0.488698  \n",
              "min                    1.000000     0.000000  \n",
              "25%                   35.000000     0.000000  \n",
              "50%                   95.000000     0.000000  \n",
              "75%                  266.000000     1.000000  \n",
              "max                15841.000000     1.000000  \n",
              "\n",
              "[8 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "id": "CdIjVFcFwFRV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = df[\"class\"]\n",
        "X = df.drop('class', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EfIfp1lXJDDe",
        "colab_type": "code",
        "outputId": "2e840fe2-18e9-4817-9bd8-a0882029070d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Understanding the capital runs attributes in the data set, \n",
        "whose upper bound is not given\n",
        "\"\"\"\n",
        "X.capital_run_length_longest.hist(bins=25)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe42869fc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPy/1ObMHvlAhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "p4JSbe1DC554",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Logistic Regression without and with normalization with cross validation"
      ]
    },
    {
      "metadata": {
        "id": "ZuhzlWGqMvu0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creating the confusion matrix storing mechanism for every cross fold"
      ]
    },
    {
      "metadata": {
        "id": "JnLHIGiuI-9f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, make_scorer\n",
        "import numpy as np\n",
        "\n",
        "\"\"\"\n",
        "The Scikit-learn confusion matrix: \n",
        "\n",
        "true negative : 0 classified as 0\n",
        "false positive : 0 classified as 1\n",
        "false negative : 1 classified as 0\n",
        "true positive : 1 classified as 1\n",
        "\n",
        "in our case, \n",
        "false positive: non spam classified as spam / non spam testing examples (0 classified as 1/class=0) \n",
        "                = fp / tn + fp\n",
        "false negative: spam classified as non spam / spam testing examples (1 classified as 0/class=1)\n",
        "                = fn / fn + tp\n",
        "overall error rate: overall misclassified examples / all examples (0 classified as 1 and 1 classified as 0/ num of examples)\n",
        "                = fp + fn / (tp + fp + fn + tn)\n",
        "\"\"\"\n",
        "\n",
        "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0,0]\n",
        "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0,1]\n",
        "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1,0]\n",
        "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1,1]\n",
        "\n",
        "def fpf(y_true, y_pred): return fp(y_true, y_pred) / (tn(y_true, y_pred) + fp(y_true, y_pred))\n",
        "def fnf(y_true, y_pred): return fn(y_true, y_pred) / (fn(y_true, y_pred) + tp(y_true, y_pred))\n",
        "def oer(y_true, y_pred): return (fp(y_true, y_pred) + fn(y_true, y_pred) )/( tn(y_true, y_pred) + fp(y_true, y_pred) + fn(y_true, y_pred) + tp(y_true, y_pred))\n",
        "\n",
        "scoring = {\n",
        "    'tp':make_scorer(tp),\n",
        "    'tn':make_scorer(tn),\n",
        "    'fp':make_scorer(fp),\n",
        "    'fn':make_scorer(fn)\n",
        "}\n",
        "\n",
        "score = {\n",
        "    'fp':make_scorer(fpf),\n",
        "    'fn':make_scorer(fnf),\n",
        "    'oe':make_scorer(oer)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j1eCT4BQM2cd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Normalizing the data set and applying logistic regression on the dataset, with confusion matrix as the scoring mechanism"
      ]
    },
    {
      "metadata": {
        "id": "ELV-hwv3NQbi",
        "colab_type": "code",
        "outputId": "b90b46d4-9cfa-4ed9-afd3-551ad6d47adf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "k = 5\n",
        "\n",
        "normalized_X=(X-X.min())/(X.max()-X.min())\n",
        "\n",
        "clf = LogisticRegression(random_state=1,multi_class='ovr', solver='lbfgs')\n",
        "\n",
        "scores = cross_validate(estimator=clf,X=normalized_X,scoring=score, y=y, cv = k)\n",
        "\n",
        "table = []\n",
        "\n",
        "for i in range(k):\n",
        "  m = [scores['test_fp'][i], scores['test_fn'][i], scores['test_oe'][i]]\n",
        "  table.append(m)\n",
        "\n",
        "  \n",
        "avg = np.sum(np.array(table), axis = 0, keepdims=True)/k\n",
        "\n",
        "  \n",
        "matrix = pd.DataFrame(table, columns = ['False Positives','False Negatives','Overall Error'])\n",
        "print(\"Errors for each cross fold: \")\n",
        "print(matrix)\n",
        "print(\"\\nAverage errors across all folds:\\n\")\n",
        "print(\"False Positives: {}\\nFalse Negatives:{}\\nOverall Error Rate: {}\\n\".format(avg[0][0],avg[0][1],avg[0][2]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Errors for each cross fold: \n",
            "   False Positives  False Negatives  Overall Error\n",
            "0         0.037634         0.245179       0.119435\n",
            "1         0.064516         0.203857       0.119435\n",
            "2         0.059140         0.159780       0.098806\n",
            "3         0.023339         0.176796       0.083787\n",
            "4         0.192101         0.223757       0.204570\n",
            "\n",
            "Average errors across all folds:\n",
            "\n",
            "False Positives: 0.07534603579081485\n",
            "False Negatives:0.2018735826370181\n",
            "Overall Error Rate: 0.12520666966761537\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m2TL8KKe84Vg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Other classifying algorithms that I have tried\n"
      ]
    },
    {
      "metadata": {
        "id": "kPBUDPsZAtiG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Using non linear support vector machine without normalization"
      ]
    },
    {
      "metadata": {
        "id": "-yegQKtSECIT",
        "colab_type": "code",
        "outputId": "144a98a2-ab79-4c68-a426-c49fb64d8a83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "import numpy as np\n",
        "\n",
        "model = svm.SVC(degree=3)\n",
        "model.fit(train_X,train_y)\n",
        "predict_y = model.predict(test_X)\n",
        "predict_y = [1 if y>=0.5 else 0 for y in predict_y]\n",
        "accuracy = np.sum(predict_y == test_y)/len(test_y)\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8218940052128584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VsCPsJo4BHzP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Using Normalized Data with SVM"
      ]
    },
    {
      "metadata": {
        "id": "0v2_CvZlBLdv",
        "colab_type": "code",
        "outputId": "5518fb15-097a-4b03-e17c-140d51b63294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "normalized_X=(X-X.min())/(X.max()-X.min())\n",
        "n_train_X, n_test_X, n_train_y, n_test_y = train_test_split(normalized_X.as_matrix(), y.as_matrix(), test_size=0.25)\n",
        "\n",
        "model = svm.SVC(degree=3)\n",
        "model.fit(n_train_X,n_train_y)\n",
        "predict_y = model.predict(n_test_X)\n",
        "accuracy = np.sum(predict_y == n_test_y)/len(n_test_y)\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8071242397914856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2SrukVQqKPdu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(estimator=model,X=normalized_X, y=y, cv = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GJwasoslKYa9",
        "colab_type": "code",
        "outputId": "8c5dce5e-6078-474b-8e7b-c00a4b56991f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(np.max(scores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8543478260869565\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n_gE3CHnKNas",
        "colab_type": "code",
        "outputId": "56da7116-2bb0-44f7-f0ea-545cfe92c2ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "np.random.seed(5)\n",
        "\n",
        "kmeans = KMeans(n_clusters = 2, random_state = 1).fit(train_X)\n",
        "\n",
        "predict_y = kmeans.predict(test_X)\n",
        "accuracy = np.sum(predict_y == (test_y))/len(test_y)\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6264118158123371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mqoyHriYBx-X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Decision Tree without and with normalization"
      ]
    },
    {
      "metadata": {
        "id": "XWH030ZNIY-g",
        "colab_type": "code",
        "outputId": "1d37753a-e85d-4c4a-f93a-5ba42b535a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "dtr = DecisionTreeRegressor(random_state=1, splitter='best')\n",
        "dtr.fit(train_X, train_y)\n",
        "predict_y = dtr.predict(test_X)\n",
        "accuracy = np.sum(predict_y == (test_y))/len(test_y)\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9252823631624674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GSLW7d1ikp17",
        "colab_type": "code",
        "outputId": "9c618e6f-9a5f-4992-8b82-9a88fa1ff4c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "normalized_X=(X-X.min())/(X.max()-X.min())\n",
        "n_train_X, n_test_X, n_train_y, n_test_y = train_test_split(normalized_X.as_matrix(), y.as_matrix(), test_size=0.25)\n",
        "dtr.fit(n_train_X, n_train_y)\n",
        "predict_y = dtr.predict(n_test_X)\n",
        "accuracy = np.sum(predict_y == (n_test_y))/len(n_test_y)\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9261511728931364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HKqN6jqJCO8I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Decision Tree Regressor with standardization (normal distribution of data)"
      ]
    },
    {
      "metadata": {
        "id": "OBOBvGAHlXTA",
        "colab_type": "code",
        "outputId": "96cb9854-f197-435c-f4b9-c1d6ff97ade9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "standardized_X=(X-X.mean())/X.std()\n",
        "n_train_X, n_test_X, n_train_y, n_test_y = train_test_split(normalized_X.as_matrix(), y.as_matrix(), test_size=0.25)\n",
        "dtr.fit(n_train_X, n_train_y)\n",
        "predict_y = dtr.predict(n_test_X)\n",
        "accuracy = np.sum(predict_y == (n_test_y))/len(n_test_y)\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.89748045178106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YziJbfdt9FOC"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Logistic Regression without and with normalization with cross validation"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "aa4675ed-13e4-4654-9074-c48d484a8985",
        "id": "s-zXvar69FOC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "clf = LogisticRegressionCV(cv=5, random_state=1,multi_class='ovr', solver='lbfgs').fit(X, y)\n",
        "print(clf.score(X,y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9311019343620952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eXNKuZfkUmIP",
        "colab_type": "code",
        "outputId": "2b577d15-c01b-4357-d1d6-706ed1617d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "normalized_X=(X-X.min())/(X.max()-X.min())\n",
        "\n",
        "clf = LogisticRegressionCV(cv=5, random_state=1,multi_class='ovr', solver='lbfgs').fit(normalized_X, y)\n",
        "print(clf.score(normalized_X,y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9330580308628559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_jOwlx_lDk8f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Logistic Regression seems to work the best along with cross validation and normalization.\n",
        "\n",
        "##In the following one, I am trying it with some of the specific features and normalization on those features."
      ]
    },
    {
      "metadata": {
        "id": "OUitiPv_SxDn",
        "colab_type": "code",
        "outputId": "27329767-82cf-4bf5-8806-eb2a9da86162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "df_features = ['capital_run_length_average',\n",
        "               'capital_run_length_longest',\n",
        "               'capital_run_length_total', \n",
        "               'word_freq_credit',\n",
        "               'char_freq_$',\n",
        "               'word_freq_meeting',\n",
        "               'char_freq_!',\n",
        "               'word_freq_conference',\n",
        "               'word_freq_table',\n",
        "                'word_freq_project',\n",
        "               'word_freq_free',\n",
        "               'word_freq_edu',\n",
        "               'word_freq_cs',\n",
        "               'char_freq_;',\n",
        "               'word_freq_direct',\n",
        "               'word_freq_receive',\n",
        "               'word_freq_money',\n",
        "               'word_freq_report',\n",
        "               'word_freq_lab',\n",
        "               'word_freq_pm',\n",
        "               'word_freq_order',\n",
        "               'word_freq_internet',\n",
        "               'word_freq_re',\n",
        "               'word_freq_our',\n",
        "               'char_freq_(',\n",
        "               'char_freq_[',\n",
        "               'word_freq_technology',\n",
        "               'word_freq_parts',\n",
        "               'word_freq_you',\n",
        "               'word_freq_your',\n",
        "               'word_freq_telnet']\n",
        "s_X = df[df_features]\n",
        "normalized_X=(s_X-s_X.min())/(s_X.max()-s_X.min())\n",
        "\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "clf = LogisticRegressionCV(cv=5, random_state=1,multi_class='ovr', solver='lbfgs').fit(normalized_X, y)\n",
        "print(clf.score(normalized_X,y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8969789176266029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8eKLNMFjFUfm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##AdaBoost with Normalization and Cross Validation"
      ]
    },
    {
      "metadata": {
        "id": "B6Abps5We7q6",
        "colab_type": "code",
        "outputId": "743da0c6-6b4a-4f4c-d3ba-7b8c7aff1c6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "normalized_X=(X-X.mean())/X.max()-X.mean()\n",
        "\n",
        "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
        "                         algorithm=\"SAMME.R\",\n",
        "                         n_estimators=200)\n",
        "\n",
        "\n",
        "\n",
        "scores = cross_val_score(estimator=bdt,X=normalized_X, y=y, cv = 10)\n",
        "print(np.mean(scores))\n",
        "print(np.min(scores))\n",
        "print(np.max(scores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9334520597512481\n",
            "0.8431372549019608\n",
            "0.9630434782608696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TuuprK8AJbCv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(estimator=bdt,X=normalized_X, y=y, cv = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fll5d8itJfH4",
        "colab_type": "code",
        "outputId": "9dc5cdea-6536-44c8-b77e-10ab1cd7c36d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "print(np.mean(scores))\n",
        "print(np.min(scores))\n",
        "print(np.max(scores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9151988601120749\n",
            "0.7932535364526659\n",
            "0.9521218715995647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZcUx5uSxKi1S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Results show that Logistic Regression and AdaBoost work best with this dataset after normalizing the data as capital length are skewed a little more then the other data dominating the answer if not min max normalized."
      ]
    }
  ]
}